{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c6d2a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15576/1708164944.py:197: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"ticker\", group_keys=False).apply(add_indicators)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Portfolio Stats ===\n",
      "Total Return            0.077424\n",
      "CAGR                    0.046097\n",
      "Vol (ann)               0.079360\n",
      "Sharpe (ann)            0.607581\n",
      "Max Drawdown           -0.096261\n",
      "Turnover (daily avg)    0.012230\n",
      "Name: Portfolio, dtype: float64\n",
      "\n",
      "=== Benchmark vs Portfolio ===\n",
      "Port Total Ret          0.077424\n",
      "Bench Total Ret         0.388476\n",
      "Port CAGR               0.046097\n",
      "Bench CAGR              0.219378\n",
      "Port Vol (ann)          0.079360\n",
      "Bench Vol (ann)         0.670414\n",
      "Port Sharpe             0.607581\n",
      "Bench Sharpe            0.626704\n",
      "Tracking Error (ann)    0.653936\n",
      "Information Ratio      -0.568762\n",
      "Beta                    0.031284\n",
      "Corr                    0.264283\n",
      "Alpha (ann)             0.035073\n",
      "Port MaxDD             -0.096261\n",
      "Bench MaxDD            -0.529775\n",
      "Name: Bench vs Port, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15576/1708164944.py:198: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[\"tgt_pos\"] = df.groupby(\"ticker\", group_keys=False).apply(lambda g: target_position(g, strat_params))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "组合与基准没有重叠日期，请检查 start_date / end_date / 数据源",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 470\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28mprint\u001b[39m(bench_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# Plots\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplot_equity_vs_benchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mportfolio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbench_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPortfolio vs QQQ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plot_drawdowns(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mportfolio\u001b[39m\u001b[38;5;124m\"\u001b[39m], bench_res, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDrawdown: Portfolio vs QQQ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    472\u001b[0m plot_rolling_corr_beta(bench_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoined\u001b[39m\u001b[38;5;124m\"\u001b[39m], window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, title_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRolling 60D\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 335\u001b[0m, in \u001b[0;36mplot_equity_vs_benchmark\u001b[0;34m(portfolio_df, bench_res, title, show, savepath, ax)\u001b[0m\n\u001b[1;32m    333\u001b[0m idx \u001b[38;5;241m=\u001b[39m port_eq\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mintersection(bench_eq\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m组合与基准没有重叠日期，请检查 start_date / end_date / 数据源\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# 画图\u001b[39;00m\n\u001b[1;32m    338\u001b[0m created_fig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: 组合与基准没有重叠日期，请检查 start_date / end_date / 数据源"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0) Imports & Config\n",
    "# =========================\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "FMP_API_BASE_URL = \"https://financialmodelingprep.com/api/v3\"\n",
    "API_KEY = \"ELnS9z5XsFT6Ne7ovmqrgxY9WOP3aFgS\"  # TODO: set me\n",
    "\n",
    "# =========================\n",
    "# 1) (Optional) Screener & Fetch\n",
    "# =========================\n",
    "@dataclass\n",
    "class Company:\n",
    "    ticker: str\n",
    "    name: str\n",
    "    market_cap: Optional[int] = None\n",
    "    country: Optional[str] = None\n",
    "    sector: Optional[str] = None\n",
    "    industry: Optional[str] = None\n",
    "\n",
    "def get_companies_smallcap_ai_semis(limit: int = 1000) -> List[Company]:\n",
    "    \"\"\"\n",
    "    Example screener: US, NASDAQ/NYSE, 'AI/semis/autonomy'-ish sectors/industries,\n",
    "    small/mid caps: 300M–20B (adjust as needed).\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"marketCapMoreThan\": 300_000_000,\n",
    "        \"marketCapLowerThan\": 20_000_000_000,\n",
    "        \"country\": \"US\",\n",
    "        \"exchange\": \"NASDAQ,NYSE\",\n",
    "        \"isActivelyTrading\": \"true\",\n",
    "        \"limit\": limit,\n",
    "        \"apikey\": API_KEY,\n",
    "    }\n",
    "    r = requests.get(f\"{FMP_API_BASE_URL}/stock-screener\", params=params)\n",
    "    r.raise_for_status()\n",
    "    data = r.json() if isinstance(r.json(), list) else []\n",
    "\n",
    "    def looks_relevant(row):\n",
    "        text = \" \".join(str(row.get(k, \"\")) for k in [\"sector\",\"industry\",\"companyName\"]).lower()\n",
    "        keys = [\"semi\", \"chip\", \"ai\", \"autonom\", \"ev\", \"vision\", \"sensor\"]\n",
    "        return any(k in text for k in keys)\n",
    "\n",
    "    comps = []\n",
    "    for row in data:\n",
    "        if row.get(\"exchangeShortName\") in {\"NASDAQ\",\"NYSE\"} and looks_relevant(row):\n",
    "            comps.append(Company(\n",
    "                ticker=row.get(\"symbol\"),\n",
    "                name=row.get(\"companyName\"),\n",
    "                market_cap=row.get(\"marketCap\"),\n",
    "                country=row.get(\"country\"),\n",
    "                sector=row.get(\"sector\"),\n",
    "                industry=row.get(\"industry\"),\n",
    "            ))\n",
    "    return comps\n",
    "\n",
    "def get_ohlcv(ticker: str, days: int = 750) -> pd.DataFrame:\n",
    "    \"\"\"Fetch OHLCV; returns columns [date, open, high, low, close, volume, ticker].\"\"\"\n",
    "    url = f\"{FMP_API_BASE_URL}/historical-price-full/{ticker}\"\n",
    "    params = {\"timeseries\": days, \"apikey\": API_KEY}\n",
    "    r = requests.get(url, params=params); r.raise_for_status()\n",
    "    data = r.json()\n",
    "    if \"historical\" not in data:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(data[\"historical\"])[[\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\"]]\n",
    "    df[\"ticker\"] = ticker\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "def merge_wide(frames: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge per-ticker frames into a wide table: date + T_open/T_close/T_volume ...\n",
    "    \"\"\"\n",
    "    out = None\n",
    "    for df in frames:\n",
    "        t = df[\"ticker\"].iloc[0]\n",
    "        slim = df[[\"date\",\"open\",\"close\",\"volume\"]].copy()\n",
    "        slim = slim.rename(columns={\"open\":f\"{t}_open\",\"close\":f\"{t}_close\",\"volume\":f\"{t}_volume\"})\n",
    "        out = slim if out is None else out.merge(slim, on=\"date\", how=\"outer\")\n",
    "    if out is not None:\n",
    "        out = out.sort_values(\"date\").reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "def ensure_long_panel(all_price_wide: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Wide → long: ['date','ticker','open','close','volume']\"\"\"\n",
    "    cols = [c for c in all_price_wide.columns if c != \"date\"]\n",
    "    tickers = sorted({c.split(\"_\")[0] for c in cols})\n",
    "    frames = []\n",
    "    for t in tickers:\n",
    "        frames.append(pd.DataFrame({\n",
    "            \"date\": all_price_wide[\"date\"],\n",
    "            \"ticker\": t,\n",
    "            \"open\": all_price_wide.get(f\"{t}_open\"),\n",
    "            \"close\": all_price_wide.get(f\"{t}_close\"),\n",
    "            \"volume\": all_price_wide.get(f\"{t}_volume\"),\n",
    "        }))\n",
    "    df = pd.concat(frames, ignore_index=True).dropna(subset=[\"open\",\"close\"])\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    return df.sort_values([\"ticker\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# 2) Indicators & Strategy\n",
    "# =========================\n",
    "def add_indicators(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    g = g.copy()\n",
    "    g[\"ret_o2o\"] = g[\"open\"].pct_change().fillna(0.0)  # execution horizon: open→open\n",
    "    for w in [5,10,20,50,200,250]:\n",
    "        g[f\"ma{w}\"] = g[\"close\"].rolling(w).mean()\n",
    "    if g[\"volume\"].notna().any():\n",
    "        g[\"vol_ma20\"] = g[\"volume\"].rolling(20).mean()\n",
    "        g[\"vol_x_ma\"] = g[\"volume\"] / g[\"vol_ma20\"]\n",
    "    else:\n",
    "        g[\"vol_ma20\"] = np.nan; g[\"vol_x_ma\"] = np.nan\n",
    "    g[\"chg_60d\"] = g[\"close\"] / g[\"close\"].shift(60) - 1.0\n",
    "    g[\"ret_3d\"] = g[\"close\"].pct_change(3)\n",
    "    g[\"ret_5d\"] = g[\"close\"].pct_change(5)\n",
    "    g[\"up_trend\"] = (g[\"ma50\"] > g[\"ma200\"]) & (g[\"ma50\"].diff() > 0) & (g[\"ma200\"].diff() > 0)\n",
    "    g[\"down_trend\"] = (g[\"ma50\"] < g[\"ma200\"]) & (g[\"ma50\"].diff() < 0)\n",
    "    g[\"pullback_hold\"] = (g[\"close\"] < g[\"ma20\"]) & (g[\"close\"] > g[\"ma50\"]) & g[\"up_trend\"]\n",
    "    win = 30\n",
    "    g[\"hh30\"] = g[\"close\"].rolling(win).max()\n",
    "    g[\"breakout_30\"] = (g[\"close\"] > g[\"hh30\"].shift(1))\n",
    "    g[\"base_break_vol\"] = g[\"vol_x_ma\"] > 1.5\n",
    "    return g\n",
    "\n",
    "@dataclass\n",
    "class StrategyParams:\n",
    "    bull_reduce_3d10: float = 0.10\n",
    "    bear_probe_5d15: float = -0.15\n",
    "    high_run_50: float = 0.50\n",
    "    low_drop_30: float = -0.30\n",
    "    vol_big_up: float = 2.0\n",
    "    vol_big_down: float = 1.5\n",
    "    max_pos_bull: float = 0.4\n",
    "    max_pos_bear: float = 0.1\n",
    "    step_small: float = 0.10\n",
    "    step_medium: float = 0.20\n",
    "    step_large: float = 0.30\n",
    "\n",
    "def target_position(g: pd.DataFrame, p: StrategyParams) -> pd.Series:\n",
    "    pos = np.zeros(len(g), dtype=float)\n",
    "    for i in range(1, len(g)):\n",
    "        pos[i] = pos[i-1]\n",
    "        cap = p.max_pos_bull if bool(g.iloc[i][\"up_trend\"]) else p.max_pos_bear\n",
    "\n",
    "        if pd.notna(g.iloc[i][\"ret_3d\"]) and g.iloc[i][\"ret_3d\"] >= p.bull_reduce_3d10:\n",
    "            pos[i] -= p.step_medium\n",
    "        if pd.notna(g.iloc[i][\"ret_5d\"]) and g.iloc[i][\"ret_5d\"] <= p.bear_probe_5d15:\n",
    "            pos[i] += p.step_medium\n",
    "\n",
    "        vx = g.iloc[i][\"vol_x_ma\"]\n",
    "        if pd.notna(vx):\n",
    "            prev_vol = g[\"vol_x_ma\"].iloc[max(0,i-3):i].mean()\n",
    "            if prev_vol < 1.0 and (g.iloc[i][\"ret_o2o\"] > 0) and vx >= p.vol_big_up:\n",
    "                pos[i] -= p.step_medium\n",
    "            if (g.iloc[i][\"ret_o2o\"] < 0) and vx >= p.vol_big_down:\n",
    "                pos[i] -= p.step_medium\n",
    "\n",
    "        if pd.notna(g.iloc[i][\"chg_60d\"]) and (g.iloc[i][\"chg_60d\"] >= p.high_run_50) and (g.iloc[i][\"ret_o2o\"] < 0):\n",
    "            if pd.notna(vx) and vx >= p.vol_big_down:\n",
    "                pos[i] = min(pos[i], p.max_pos_bear)\n",
    "\n",
    "        if pd.notna(g.iloc[i][\"chg_60d\"]) and (g.iloc[i][\"chg_60d\"] <= p.low_drop_30) and (g.iloc[i][\"ret_o2o\"] > 0):\n",
    "            if pd.notna(vx) and vx >= p.vol_big_down:\n",
    "                pos[i] += p.step_medium\n",
    "\n",
    "        if bool(g.iloc[i][\"up_trend\"]) and bool(g.iloc[i][\"breakout_30\"]) and bool(g.iloc[i][\"base_break_vol\"]):\n",
    "            pos[i] += p.step_large\n",
    "\n",
    "        if bool(g.iloc[i][\"pullback_hold\"]):\n",
    "            pos[i] += p.step_small\n",
    "        if bool(g.iloc[i][\"down_trend\"]) and (g.iloc[i][\"close\"] < g.iloc[i][\"ma50\"]):\n",
    "            pos[i] -= p.step_medium\n",
    "\n",
    "        pos[i] = float(np.clip(pos[i], 0.0, cap))\n",
    "    return pd.Series(pos, index=g.index, name=\"tgt_pos\")\n",
    "\n",
    "# =========================\n",
    "# 3) Backtest\n",
    "# =========================\n",
    "@dataclass\n",
    "class BTParams:\n",
    "    fee_bps: float = 5.0\n",
    "    slip_bps: float = 5.0\n",
    "\n",
    "def backtest(panel_long: pd.DataFrame,\n",
    "             strat_params: StrategyParams = StrategyParams(),\n",
    "             bt_params: BTParams = BTParams(),\n",
    "             start_date: Optional[str] = None,\n",
    "             end_date: Optional[str] = None) -> Dict[str, pd.DataFrame]:\n",
    "    df = panel_long.sort_values([\"ticker\",\"date\"]).copy()\n",
    "    df = df.groupby(\"ticker\", group_keys=False).apply(add_indicators)\n",
    "    df[\"tgt_pos\"] = df.groupby(\"ticker\", group_keys=False).apply(lambda g: target_position(g, strat_params))\n",
    "    df[\"pos_exec\"] = df.groupby(\"ticker\")[\"tgt_pos\"].shift(1).fillna(0.0)\n",
    "    fee = (bt_params.fee_bps + bt_params.slip_bps) / 1e4\n",
    "    df[\"turnover\"] = df.groupby(\"ticker\")[\"pos_exec\"].diff().abs().fillna(df[\"pos_exec\"])\n",
    "    df[\"cost\"] = df[\"turnover\"] * fee\n",
    "    df[\"daily_pnl\"] = df[\"pos_exec\"] * df[\"ret_o2o\"]\n",
    "    df[\"daily_pnl_net\"] = df[\"daily_pnl\"] - df[\"cost\"]\n",
    "    df[\"equity\"] = (1 + df[\"daily_pnl_net\"]).groupby(df[\"ticker\"]).cumprod()\n",
    "\n",
    "    if start_date: df = df[df[\"date\"] >= pd.to_datetime(start_date)]\n",
    "    if end_date:   df = df[df[\"date\"] <= pd.to_datetime(end_date)]\n",
    "\n",
    "    port = df.groupby(\"date\")[\"daily_pnl_net\"].mean().to_frame(\"ret\")\n",
    "    port[\"equity\"] = (1 + port[\"ret\"]).cumprod()\n",
    "\n",
    "    ann = 252\n",
    "    def max_dd(s):\n",
    "        pk = s.cummax()\n",
    "        return (s/pk - 1.0).min()\n",
    "\n",
    "    stats = {\n",
    "        \"Total Return\": (port[\"equity\"].iloc[-1] - 1.0) if len(port) else np.nan,\n",
    "        \"CAGR\": (port[\"equity\"].iloc[-1] ** (ann/len(port)) - 1.0) if len(port) else np.nan,\n",
    "        \"Vol (ann)\": port[\"ret\"].std() * np.sqrt(ann) if len(port)>1 else np.nan,\n",
    "        \"Sharpe (ann)\": (port[\"ret\"].mean()/port[\"ret\"].std()*np.sqrt(ann)) if port[\"ret\"].std()>0 else np.nan,\n",
    "        \"Max Drawdown\": max_dd(port[\"equity\"]) if len(port)>1 else np.nan,\n",
    "        \"Turnover (daily avg)\": df.groupby(\"date\")[\"turnover\"].mean().mean() if len(df)>0 else np.nan,\n",
    "    }\n",
    "    return {\"panel\": df, \"portfolio\": port, \"stats\": pd.Series(stats, name=\"Portfolio\")}\n",
    "\n",
    "# =========================\n",
    "# 4) Benchmark & Metrics\n",
    "# =========================\n",
    "def get_benchmark_price(ticker: str, days: int = 1500) -> pd.DataFrame:\n",
    "    url = f\"{FMP_API_BASE_URL}/historical-price-full/{ticker}\"\n",
    "    params = {\"timeseries\": days, \"apikey\": API_KEY}\n",
    "    r = requests.get(url, params=params); r.raise_for_status()\n",
    "    data = r.json()\n",
    "    if \"historical\" not in data:\n",
    "        raise ValueError(f\"No historical data for {ticker}\")\n",
    "    df = pd.DataFrame(data[\"historical\"])[[\"date\",\"open\",\"close\"]].copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "def universe_equal_weight_benchmark(panel_long: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = panel_long.sort_values([\"ticker\",\"date\"]).copy()\n",
    "    df[\"ret_cc\"] = df.groupby(\"ticker\")[\"close\"].pct_change()\n",
    "    bench = df.groupby(\"date\")[\"ret_cc\"].mean().to_frame(\"bench_ret\").fillna(0.0)\n",
    "    bench[\"equity\"] = (1 + bench[\"bench_ret\"]).cumprod()\n",
    "    return bench.reset_index()\n",
    "\n",
    "def benchmark_metrics(port: pd.DataFrame,\n",
    "                      bench_df: pd.DataFrame,\n",
    "                      start_date: Optional[str] = None,\n",
    "                      end_date: Optional[str] = None,\n",
    "                      use_open_to_open: bool = True) -> Dict[str, pd.Series]:\n",
    "    p = port.reset_index().rename(columns={\"index\":\"date\"}) if \"date\" not in port.columns else port.copy()\n",
    "    p[\"date\"] = pd.to_datetime(p[\"date\"])\n",
    "    if start_date: p = p[p[\"date\"] >= pd.to_datetime(start_date)]\n",
    "    if end_date:   p = p[p[\"date\"] <= pd.to_datetime(end_date)]\n",
    "\n",
    "    b = bench_df.copy()\n",
    "    b[\"date\"] = pd.to_datetime(b[\"date\"])\n",
    "    if start_date: b = b[b[\"date\"] >= pd.to_datetime(start_date)]\n",
    "    if end_date:   b = b[b[\"date\"] <= pd.to_datetime(end_date)]\n",
    "\n",
    "    if \"bench_ret\" not in b.columns:\n",
    "        b[\"bench_ret\"] = (b[\"open\"].pct_change() if use_open_to_open else b[\"close\"].pct_change()).fillna(0.0)\n",
    "    b = b[[\"date\",\"bench_ret\"]]\n",
    "\n",
    "    df = p.merge(b, on=\"date\", how=\"inner\").dropna(subset=[\"ret\",\"bench_ret\"])\n",
    "    if len(df) < 2:\n",
    "        return {\"msg\": \"Not enough overlap\"}\n",
    "\n",
    "    port_eq = (1 + df[\"ret\"]).cumprod()\n",
    "    bench_eq = (1 + df[\"bench_ret\"]).cumprod()\n",
    "\n",
    "    ann = 252\n",
    "    def max_dd(s):\n",
    "        pk = s.cummax()\n",
    "        return (s/pk - 1.0).min()\n",
    "\n",
    "    cov = np.cov(df[\"ret\"], df[\"bench_ret\"], ddof=1)\n",
    "    beta = cov[0,1] / cov[1,1] if cov[1,1] != 0 else np.nan\n",
    "\n",
    "    stats = {\n",
    "        \"Port Total Ret\": port_eq.iloc[-1] - 1,\n",
    "        \"Bench Total Ret\": bench_eq.iloc[-1] - 1,\n",
    "        \"Port CAGR\": port_eq.iloc[-1] ** (ann/len(df)) - 1,\n",
    "        \"Bench CAGR\": bench_eq.iloc[-1] ** (ann/len(df)) - 1,\n",
    "        \"Port Vol (ann)\": df[\"ret\"].std()*np.sqrt(ann),\n",
    "        \"Bench Vol (ann)\": df[\"bench_ret\"].std()*np.sqrt(ann),\n",
    "        \"Port Sharpe\": (df[\"ret\"].mean()/df[\"ret\"].std())*np.sqrt(ann) if df[\"ret\"].std()>0 else np.nan,\n",
    "        \"Bench Sharpe\": (df[\"bench_ret\"].mean()/df[\"bench_ret\"].std())*np.sqrt(ann) if df[\"bench_ret\"].std()>0 else np.nan,\n",
    "        \"Tracking Error (ann)\": (df[\"ret\"]-df[\"bench_ret\"]).std()*np.sqrt(ann),\n",
    "        \"Information Ratio\": ((df[\"ret\"]-df[\"bench_ret\"]).mean()/ (df[\"ret\"]-df[\"bench_ret\"]).std())*np.sqrt(ann) if (df[\"ret\"]-df[\"bench_ret\"]).std()>0 else np.nan,\n",
    "        \"Beta\": beta,\n",
    "        \"Corr\": np.corrcoef(df[\"ret\"], df[\"bench_ret\"])[0,1],\n",
    "        \"Alpha (ann)\": (df[\"ret\"].mean() - beta*df[\"bench_ret\"].mean())*ann if not np.isnan(beta) else np.nan,\n",
    "        \"Port MaxDD\": max_dd(port_eq),\n",
    "        \"Bench MaxDD\": max_dd(bench_eq),\n",
    "    }\n",
    "    return {\"joined\": df, \"stats\": pd.Series(stats, name=\"Bench vs Port\"),\n",
    "            \"port_equity\": port_eq, \"bench_equity\": bench_eq}\n",
    "\n",
    "# =========================\n",
    "# 5) Plots (single-plot, no colors set)\n",
    "# =========================\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def plot_equity_vs_benchmark(portfolio_df, bench_res, title=\"Portfolio vs Benchmark\",\n",
    "                             show=True, savepath=None, ax=None):\n",
    "    # 准备数据\n",
    "    p = portfolio_df.copy()\n",
    "    if \"date\" in p.columns:\n",
    "        p = p.set_index(\"date\")\n",
    "    p.index = pd.to_datetime(p.index)\n",
    "    if \"equity\" not in p.columns or p[\"equity\"].empty:\n",
    "        raise ValueError(\"portfolio_df 缺少 'equity' 列或为空\")\n",
    "\n",
    "    port_eq = p[\"equity\"].dropna()\n",
    "\n",
    "    bench_eq = bench_res.get(\"bench_equity\", None)\n",
    "    if bench_eq is None:\n",
    "        j = bench_res[\"joined\"].copy()\n",
    "        if len(j) == 0:\n",
    "            raise ValueError(\"benchmark joined 为空，没有可绘制的基准数据（检查日期对齐）\")\n",
    "        j[\"date\"] = pd.to_datetime(j[\"date\"])\n",
    "        j = j.sort_values(\"date\")\n",
    "        j[\"bench_equity\"] = (1 + j[\"bench_ret\"]).cumprod()\n",
    "        bench_eq = j.set_index(\"date\")[\"bench_equity\"]\n",
    "    bench_eq = bench_eq.dropna()\n",
    "\n",
    "    # 对齐\n",
    "    idx = port_eq.index.intersection(bench_eq.index)\n",
    "    if len(idx) == 0:\n",
    "        raise ValueError(\"组合与基准没有重叠日期，请检查 start_date / end_date / 数据源\")\n",
    "\n",
    "    # 画图\n",
    "    created_fig = False\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        created_fig = True\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    ax.plot(port_eq.loc[idx].index, port_eq.loc[idx].values, label=\"Portfolio\")\n",
    "    ax.plot(bench_eq.loc[idx].index, bench_eq.loc[idx].values, label=\"Benchmark\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Equity\")\n",
    "    ax.legend()\n",
    "\n",
    "    if savepath:\n",
    "        fig.savefig(savepath, bbox_inches=\"tight\", dpi=150)\n",
    "    if show and created_fig:\n",
    "        plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "def plot_drawdowns(portfolio_df, bench_res, title=\"Drawdowns\",\n",
    "                   show=True, savepath=None, ax=None):\n",
    "    def dd(s):\n",
    "        pk = s.cummax()\n",
    "        return s/pk - 1.0\n",
    "\n",
    "    p = portfolio_df.copy()\n",
    "    if \"date\" in p.columns:\n",
    "        p = p.set_index(\"date\")\n",
    "    p.index = pd.to_datetime(p.index)\n",
    "    if \"equity\" not in p.columns or p[\"equity\"].empty:\n",
    "        raise ValueError(\"portfolio_df 缺少 'equity' 列或为空\")\n",
    "    port_dd = dd(p[\"equity\"].dropna())\n",
    "\n",
    "    bench_eq = bench_res.get(\"bench_equity\", None)\n",
    "    if bench_eq is None:\n",
    "        j = bench_res[\"joined\"].copy()\n",
    "        if len(j) == 0:\n",
    "            raise ValueError(\"benchmark joined 为空，没有可绘制的基准数据（检查日期对齐）\")\n",
    "        j[\"date\"] = pd.to_datetime(j[\"date\"])\n",
    "        j = j.sort_values(\"date\")\n",
    "        j[\"bench_equity\"] = (1 + j[\"bench_ret\"]).cumprod()\n",
    "        bench_eq = j.set_index(\"date\")[\"bench_equity\"]\n",
    "    bench_eq = bench_eq.dropna()\n",
    "    bench_dd = dd(bench_eq)\n",
    "\n",
    "    idx = port_dd.index.intersection(bench_dd.index)\n",
    "    if len(idx) == 0:\n",
    "        raise ValueError(\"组合与基准没有重叠日期，请检查 start_date / end_date / 数据源\")\n",
    "\n",
    "    created_fig = False\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        created_fig = True\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    ax.plot(port_dd.loc[idx].index, port_dd.loc[idx].values, label=\"Portfolio\")\n",
    "    ax.plot(bench_dd.loc[idx].index, bench_dd.loc[idx].values, label=\"Benchmark\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Drawdown\")\n",
    "    ax.legend()\n",
    "\n",
    "    if savepath:\n",
    "        fig.savefig(savepath, bbox_inches=\"tight\", dpi=150)\n",
    "    if show and created_fig:\n",
    "        plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "def plot_rolling_corr_beta(bench_joined: pd.DataFrame, window=60, title_prefix=\"Rolling\"):\n",
    "    j = bench_joined.copy()\n",
    "    j[\"date\"] = pd.to_datetime(j[\"date\"])\n",
    "    j = j.set_index(\"date\").sort_index()\n",
    "    r = j[\"ret\"]; b = j[\"bench_ret\"]\n",
    "\n",
    "    roll_corr = r.rolling(window).corr(b)\n",
    "    # rolling beta via Cov/Var\n",
    "    beta = []\n",
    "    idx = r.index\n",
    "    for i in range(len(idx)):\n",
    "        j0 = max(0, i-window+1)\n",
    "        rv, bv = r.iloc[j0:i+1], b.iloc[j0:i+1]\n",
    "        if len(rv) < 2 or bv.var() == 0: beta.append(np.nan)\n",
    "        else: beta.append(np.cov(rv, bv, ddof=1)[0,1]/bv.var())\n",
    "    roll_beta = pd.Series(beta, index=idx)\n",
    "\n",
    "    plt.figure(); plt.plot(roll_corr.index, roll_corr.values)\n",
    "    plt.title(f\"{title_prefix} Correlation ({window}D)\"); plt.xlabel(\"Date\"); plt.ylabel(\"Correlation\"); plt.show()\n",
    "\n",
    "    plt.figure(); plt.plot(roll_beta.index, roll_beta.values)\n",
    "    plt.title(f\"{title_prefix} Beta ({window}D)\"); plt.xlabel(\"Date\"); plt.ylabel(\"Beta\"); plt.show()\n",
    "\n",
    "def plot_calendar_returns(portfolio: pd.DataFrame, title=\"Calendar-Year Returns\"):\n",
    "    p = portfolio.copy()\n",
    "    if \"date\" in p.columns: p = p.set_index(\"date\")\n",
    "    p.index = pd.to_datetime(p.index)\n",
    "    yearly = (1 + p[\"ret\"]).groupby(pd.Grouper(freq=\"A\")).apply(lambda x: (1+x).prod() - 1.0)\n",
    "    yearly = yearly.dropna()\n",
    "    plt.figure(); plt.bar(yearly.index.year, yearly.values)\n",
    "    plt.title(title); plt.xlabel(\"Year\"); plt.ylabel(\"Return\"); plt.show()\n",
    "\n",
    "# =========================\n",
    "# 6) Example: minimal run\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # (A) pick tickers manually (recommended for control), or use screener above\n",
    "    tickers = [\"AMD\",\"NVDA\",\"AVGO\",\"TSM\"]  # edit as you like\n",
    "\n",
    "    frames = []\n",
    "    for t in tickers:\n",
    "        df_t = get_ohlcv(t, days=1000)\n",
    "        if not df_t.empty:\n",
    "            frames.append(df_t)\n",
    "    if not frames:\n",
    "        raise SystemExit(\"No data fetched.\")\n",
    "\n",
    "    wide = merge_wide(frames)\n",
    "    panel = ensure_long_panel(wide)\n",
    "\n",
    "    # Backtest (open→open model), with date window\n",
    "    res = backtest(panel, start_date=\"2024-01-01\", end_date=None)\n",
    "    print(\"\\n=== Portfolio Stats ===\")\n",
    "    print(res[\"stats\"])\n",
    "\n",
    "    # Benchmark: QQQ (open→open to match model)\n",
    "    bench_px = get_benchmark_price(\"TSLA\", days=1500)\n",
    "    bench_res = benchmark_metrics(res[\"portfolio\"], bench_px, start_date=\"2024-01-01\", use_open_to_open=True)\n",
    "    print(\"\\n=== Benchmark vs Portfolio ===\")\n",
    "    print(bench_res[\"stats\"])\n",
    "\n",
    "    # Plots\n",
    "    fig, ax = plot_equity_vs_benchmark(res[\"portfolio\"], bench_res, title=\"Portfolio vs QQQ\")\n",
    "    fig, ax = plot_drawdowns(res[\"portfolio\"], bench_res, title=\"Drawdown: Portfolio vs QQQ\")\n",
    "    plot_rolling_corr_beta(bench_res[\"joined\"], window=60, title_prefix=\"Rolling 60D\")\n",
    "    plot_calendar_returns(res[\"portfolio\"], title=\"Calendar Returns (Portfolio)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5cdc7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portfolio len: 918\n",
      "bench joined len: 918\n",
      "date range: 2022-01-03 00:00:00 -> 2025-08-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"portfolio len:\", len(res[\"portfolio\"]))\n",
    "print(\"bench joined len:\", len(bench_res[\"joined\"]))\n",
    "if len(bench_res[\"joined\"]) > 0:\n",
    "    print(\"date range:\",\n",
    "          bench_res[\"joined\"][\"date\"].min(),\n",
    "          \"->\",\n",
    "          bench_res[\"joined\"][\"date\"].max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
