{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import dspy\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo  # Python 3.9+\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env from project root (install python-dotenv if needed: pip install python-dotenv)\n",
    "load_dotenv()\n",
    "# OpenAI key used by dspy; allow several variable names for flexibility\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or os.getenv('OPENAI_KEY') or os.getenv('OPENAI')\n",
    "if not OPENAI_API_KEY:\n",
    "    raise RuntimeError('OpenAI API key not found. Set OPENAI_API_KEY in your .env file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f00597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching PR Newswire items for 2025-09-14...\n",
      "Added 200 new items. Total now: 200\n",
      "         date      time                                              title  \\\n",
      "0  2025-09-14  12:00 ET  LNTH INVESTOR ALERT: Bronstein, Gewirtz & Gros...   \n",
      "1  2025-09-14  10:38 ET  ADNOC Gas wird in den FTSE Emerging Index aufg...   \n",
      "2  2025-09-14  08:30 ET  SHAREHOLDER REMINDER: Faruqi & Faruqi, LLP Inv...   \n",
      "3  2025-09-14  00:24 ET  Supermicro begint met bulkleveringen van NVIDI...   \n",
      "4  2025-09-14      None  Sep 13, 2025, 23:57 ETParkland Corporation anu...   \n",
      "\n",
      "                                                link  \\\n",
      "0  https://www.prnewswire.com/news-releases/lnth-...   \n",
      "1  https://www.prnewswire.com/news-releases/adnoc...   \n",
      "2  https://www.prnewswire.com/news-releases/share...   \n",
      "3  https://www.prnewswire.com/news-releases/super...   \n",
      "4  https://www.prnewswire.com/news-releases/parkl...   \n",
      "\n",
      "                                             content  has_exchange  \n",
      "0  NEW YORK,Sept. 14, 2025/PRNewswire/ -- Attorne...             1  \n",
      "1  Die Aufnahme von ADNOC Gas in den FTSE Index s...             0  \n",
      "2  Faruqi & Faruqi, LLP Securities Litigation Par...             1  \n",
      "3  SAN JOSE, Calif.,14 september 2025/PRNewswire/...             1  \n",
      "4  CALGARY, Alberta,13 de septiembre de 2025/PRNe...             0  \n"
     ]
    }
   ],
   "source": [
    "BASE_URL = \"https://www.prnewswire.com/news-releases/all-public-company-news/\"\n",
    "\n",
    "def try_request(url, timeout=10):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=timeout)\n",
    "        return r if r.status_code == 200 else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_time_and_clean_title(raw_title: str):\n",
    "    # Matches \"09:50 ETTitle...\" or \"9:05 AM ET Title...\"\n",
    "    m = re.match(r\"^(\\d{1,2}:\\d{2}\\s*(?:[AP]M\\s*)?ET)\\s*(.*)\", raw_title, re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1).strip(), m.group(2).strip()\n",
    "    return None, raw_title.strip()\n",
    "\n",
    "def get_article_content(article_url: str):\n",
    "    resp = try_request(article_url)\n",
    "    if not resp:\n",
    "        return \"\"\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "    paragraphs = [\n",
    "        p.get_text(strip=True)\n",
    "        for p in soup.find_all('p')\n",
    "        if len(p.get_text(strip=True)) > 50\n",
    "    ]\n",
    "    content = \"\\n\\n\".join(paragraphs[:5])\n",
    "\n",
    "    # Trim at DISCLAIMER (case-insensitive)\n",
    "    cut = content.upper().find(\"DISCLAIMER\")\n",
    "    if cut != -1:\n",
    "        content = content[:cut].strip()\n",
    "    return content\n",
    "\n",
    "def flag_has_exchange(text: str):\n",
    "    pattern = re.compile(r'(NYSE|DOW|NASDAQ)', re.IGNORECASE)\n",
    "    return 1 if pattern.search(text or \"\") else 0\n",
    "\n",
    "def fetch_new_until_seen(df_base: pd.DataFrame, max_pages=10, sleep_between=0.2):\n",
    "    \"\"\"\n",
    "    Stream today's items (America/Chicago). Stop at the first already-seen link.\n",
    "    Returns a DataFrame with only the newly fetched rows (same schema as df_base).\n",
    "    \"\"\"\n",
    "    now_ct = datetime.now(ZoneInfo(\"America/Chicago\"))\n",
    "    year, month, day = now_ct.year, now_ct.month, now_ct.day\n",
    "    date_str = f\"{year:04d}-{month:02d}-{day:02d}\"\n",
    "    print(f\"Fetching PR Newswire items for {date_str}...\")\n",
    "\n",
    "    # ✅ Only keep today's links for faster lookup\n",
    "    if df_base is not None and not df_base.empty and \"link\" in df_base.columns and \"date\" in df_base.columns:\n",
    "        seen_links = set(df_base.loc[df_base[\"date\"] == date_str, \"link\"].astype(str))\n",
    "    else:\n",
    "        seen_links = set()\n",
    "\n",
    "    collected = []\n",
    "    seen_this_run = set()  # avoid duplicates within the same crawl\n",
    "    stop = False\n",
    "\n",
    "    for page in range(1, max_pages + 1):\n",
    "        if stop:\n",
    "            break\n",
    "\n",
    "        list_url = f\"{BASE_URL}?month={month:02d}&day={day:02d}&year={year}&page={page}&pagesize=100\"\n",
    "        resp = try_request(list_url)\n",
    "        if not resp:\n",
    "            break\n",
    "\n",
    "        soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "        anchors = soup.find_all(\"a\", href=re.compile(r\"^/news-releases/.*\\.html$\"))\n",
    "        if not anchors:\n",
    "            break\n",
    "\n",
    "        for a in anchors:\n",
    "            href = a.get(\"href\")\n",
    "            if not href:\n",
    "                continue\n",
    "            full_url = \"https://www.prnewswire.com\" + href\n",
    "\n",
    "            # ✅ Early stop: first already-seen *today* link => stop scanning\n",
    "            if full_url in seen_links:\n",
    "                stop = True\n",
    "                break\n",
    "\n",
    "            if full_url in seen_this_run:\n",
    "                continue\n",
    "            seen_this_run.add(full_url)\n",
    "\n",
    "            raw_title = a.get_text(strip=True)\n",
    "            news_time, title = extract_time_and_clean_title(raw_title)\n",
    "\n",
    "            content = get_article_content(full_url)\n",
    "            has_exch = flag_has_exchange(content)\n",
    "\n",
    "            collected.append({\n",
    "                \"date\": date_str,\n",
    "                \"time\": news_time,\n",
    "                \"title\": title,\n",
    "                \"link\": full_url,\n",
    "                \"content\": content,\n",
    "                \"has_exchange\": has_exch,\n",
    "            })\n",
    "\n",
    "            time.sleep(sleep_between)\n",
    "\n",
    "    return pd.DataFrame(collected)\n",
    "\n",
    "def main(df_base: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    df_base must have columns:\n",
    "    ['date','time','title','link','content','has_exchange']\n",
    "    \"\"\"\n",
    "    # Ensure schema (in case caller passes empty/partial df)\n",
    "    required_cols = ['date','time','title','link','content','has_exchange']\n",
    "    if df_base is None or df_base.empty:\n",
    "        df_base = pd.DataFrame(columns=required_cols)\n",
    "    else:\n",
    "        for c in required_cols:\n",
    "            if c not in df_base.columns:\n",
    "                df_base[c] = None\n",
    "\n",
    "    df_new = fetch_new_until_seen(df_base, max_pages=10, sleep_between=0.15)\n",
    "    if df_new.empty:\n",
    "        print(\"No new items found (hit an already-seen link right away).\")\n",
    "        return df_base\n",
    "\n",
    "    df_out = pd.concat([df_base, df_new], ignore_index=True)\n",
    "    print(f\"Added {len(df_new)} new items. Total now: {len(df_out)}\")\n",
    "    return df_out, df_new\n",
    "\n",
    "# ---------- Example usage ----------\n",
    "# Initialize once (or load your existing df_base)\n",
    "columns = ['date','time','title','link','content','has_exchange']\n",
    "df_base = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Update df_base efficiently with early-stop scanning\n",
    "df_out, df_new = main(df_base)\n",
    "print(df_new.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a86c0e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 5",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_news \u001b[38;5;241m=\u001b[39m \u001b[43mdf_new\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_new\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhas_exchange\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_news)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/series.py:1130\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/series.py:1246\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1246\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 5"
     ]
    }
   ],
   "source": [
    "test_news = df_new[df_new['has_exchange'] == 1]['content'][5]\n",
    "print(test_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04569791",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_news = \"\"\"VANCOUVER, BC, Sept. 10, 2025 /PRNewswire/ -- Corporate treasury companies surge an average of 150% within 24 hours of announcing crypto adoption strategies, according to a 2025 Animoca Brands report[1], as digital asset treasuries amass $113 billion in Bitcoin stockpiles through September 2025[2]. The explosive momentum reflects a fundamental shift from traditional cash reserves to strategic cryptocurrency accumulation, with Crypto.com reporting over 90 public companies now holding Bitcoin on their balance sheets[3] as corporate America embraces digital assets as inflation hedges and growth catalysts. This treasury transformation is helping to position companies embracing it, including CEA Industries, Inc. (NASDAQ: BNC), Kindly MD, Inc. (NASDAQ: NAKA), Metaplanet Inc. (OTCQX: MTPLF), The Smarter Web Company PLC (OTCQB: TSWCF), and Cipher Mining Inc. (NASDAQ: CIFR).\n",
    "\n",
    "Institutional demand accelerates as BlackRock's Bitcoin ETF attracted $289.8 million in fresh inflows on September 4 alone[4], while Strategy's treasury model has delivered 257% returns by aggressively accumulating over 582,000 BTC worth $62 billion[5]. The convergence of regulatory clarity, ETF accessibility, and corporate adoption creates unprecedented supply-demand dynamics, with analysts projecting continued institutional accumulation as pension funds and sovereign wealth entities prepare their own digital asset allocations, thus rewarding companies that establish strategic positions before the broader institutional wave arrives.\n",
    "\n",
    "CEA Industries (NASDAQ: BNC) recently strengthened its institutional foundation through the appointment of Dr. Russell Read, Ph.D., CFA, as a non-executive board member, further cementing its transformation into a premier BNB treasury operation. Dr. Read's extensive background managing capital at CalPERS, Alaska Permanent Fund Corporation, and Gulf Investment Corporation—where he oversaw hundreds of billions across global markets—brings heavyweight institutional expertise to the Colorado-based firm's aggressive BNB accumulation strategy.\n",
    "\n",
    "This leadership enhancement coincides with CEA Industries' rapid expansion of its BNB position, which has grown to 388,888 tokens worth approximately $330 million. The company maintains its ambitious goal of securing 1% of BNB's total circulating supply by early 2026, representing a concentrated bet on the world's most actively used blockchain network for daily transactions.\n",
    "\n",
    "\"Since the announcement of their BNB Treasury, CEA Industries has swiftly established itself as a global leader in digital asset treasury management,\" said Dr. Read. \"I look forward to working with David [Namdar, CEO of CEA Industries (BNC)] and the Board to further strengthen governance, expand institutional engagement, and position CEA Industries for long-term success.\"\n",
    "\n",
    "BNC's strategic approach centers entirely on BNB's foundational role within the most utilized blockchain ecosystem for everyday transactions and decentralized finance operations. Instead of diversifying across multiple digital assets, the company has committed exclusively to BNB's ecosystem potential, believing this focused strategy maximizes exposure to network effects while enabling direct participation in on-chain yield opportunities.\n",
    "\n",
    "This concentrated approach emerged from a transformative private placement of $500 million that completely restructured the company from its previous operations into a pure-play BNB treasury vehicle. The funding round drew over 140 institutional and crypto-native investors, including Pantera Capital, Arche Capital, ExodusPoint Capital Management, and Blockchain.com, with Cantor Fitzgerald & Co. acting as exclusive placement agent and lead financial advisor.\n",
    "\n",
    "BNB's attraction lies in its distinctive blend of utility and deflationary mechanics. The token powers millions of daily transactions while delivering staking rewards and benefiting from quarterly supply burns through automated reduction mechanisms. Unlike speculative digital assets, BNB demonstrates consistent economic utility across trading infrastructure, payment networks, and decentralized application environments.\n",
    "\n",
    "CEA Industries' leadership team merges profound crypto expertise with traditional finance experience. CEO David Namdar previously co-founded Galaxy Digital and helped develop institutional crypto trading infrastructure. Dr. Read's addition provides sovereign wealth fund management expertise spanning decades and multiple regions. Hans Thomas of 10X Capital oversees treasury operations, contributing public company and capital markets knowledge to the BNB accumulation framework.\n",
    "\n",
    "The company fills a critical market void for U.S. investors lacking direct BNB access through traditional brokerage platforms. BNC delivers regulated market exposure to BNB's performance without requiring cryptocurrency wallets, exchange registrations, or technical blockchain expertise. Investors gain BNB ecosystem exposure through conventional equity ownership in a NASDAQ-listed entity.\n",
    "\n",
    "Current market dynamics favor BNC's strategy, with BNB recently approaching $900 price levels[6] while the broader BNB Chain ecosystem maintains over $120 billion in total market capitalization[7]. Should warrant exercises reach their maximum potential of $750 million in additional capital, CEA Industries could accumulate BNB holdings exceeding $1.25 billion in aggregate value.\n",
    "\n",
    "BNC represents a strategic wager on blockchain infrastructure adoption within traditional financial systems. For investors seeking regulated exposure to cryptocurrency markets without direct digital asset ownership, CEA Industries provides institutional-grade access to one of the most actively utilized blockchain networks in global finance.\n",
    "\n",
    "CONTINUED… Read this and more news for CEA Industries at: https://equity-insider.com/2025/08/13/beat-wall-street-to-the-trade-that-500-million-just-backed/\n",
    "\n",
    "Kindly MD, Inc. (NASDAQ: NAKA) has made a significant strategic investment with its subsidiary Nakamoto Holdings Inc. committing up to $30 million to Metaplanet Inc.'s (OTCQX: MTPLF), international equity financing, marking Nakamoto's largest single investment to date and its first in an Asian public company with a Bitcoin treasury strategy.\n",
    "\n",
    "The investment in Japan's first and leading Bitcoin treasury company is expected to be funded on September 16, 2025, with proceeds allocated primarily to Bitcoin purchases. This transaction reinforces KindlyMD's position as both a healthcare services provider and Bitcoin treasury vehicle following its August 2025 merger with Nakamoto Holdings Inc.\n",
    "\n",
    "\"Metaplanet has established itself as a leader in Japan's Bitcoin landscape through its commitment to advancing financial innovation and driving the global adoption of Bitcoin,\" said David Bailey, Chairman and CEO of KindlyMD. \"By positioning Bitcoin as the cornerstone of its financial approach, Metaplanet has become one of Japan's leading public companies and a global leader in corporate Bitcoin strategies. We are proud to support their mission and believe this investment will further strengthen the global network of companies placing Bitcoin at the center of institutional finance.\"\n",
    "\n",
    "Metaplanet continues to pioneer Japan's Bitcoin-backed fixed income market with shareholders recently authorizing two classes of perpetual preferred shares designed to optimize long-term Bitcoin accumulation. The strategic partnership unites KindlyMD's healthcare expertise with Nakamoto's vision of integrating Bitcoin into global capital markets, creating a diversified entity focused on both healthcare innovation and Bitcoin treasury management.\n",
    "\n",
    "The Smarter Web Company PLC (OTCQB: TSWCF) has purchased an additional 30 Bitcoin at an average price of £83,404.85 per Bitcoin ($112,846 per Bitcoin), bringing total holdings to 2,470 Bitcoin as part of \"The 10 Year Plan\" ongoing treasury policy. The London-based company has achieved an impressive Year-to-Date BTC Yield of 56,796% on its treasury and a 30 Day BTC Yield of 18%, with total Bitcoin purchases now valued at £203,580,051. The web design and development company has adopted Bitcoin as a core component of its financial strategy while maintaining approximately £400,000 in net cash available for future Bitcoin deployment.\n",
    "\n",
    "The company's board considers Bitcoin to be a strategic store of value and growth vehicle for reserves, though they acknowledge the high-risk nature and volatility associated with cryptocurrency investments. The Smarter Web Company continues to explore opportunities through organic growth and corporate acquisitions while integrating its Bitcoin Treasury Policy into its overall business strategy.\n",
    "\n",
    "With Bitcoin forming what the company believes is a core part of the future global financial system, the firm maintains transparency with investors regarding both the opportunities and risks associated with its substantial cryptocurrency holdings.\n",
    "\n",
    "Cipher Mining Inc. (NASDAQ: CIFR) has produced 241 BTC in August while maintaining 1,414 BTC in treasury holdings after selling 42 BTC as part of regular treasury management processes, with the company's Black Pearl Phase I facility accounting for approximately 39% of total Bitcoin production.\n",
    "\n",
    "The industrial-scale Bitcoin mining operation deployed 115,000 mining rigs generating 23.0 EH/s of operating hashrate at 17.3 J/TH fleet efficiency, positioning the company as a significant Bitcoin accumulator through mining operations. Cipher continues scaling production with Black Pearl Phase I expected to reach approximately 10 EH/s by the end of the third quarter, bringing total self-mining hashrate to approximately 23.5 EH/s.\n",
    "\n",
    "The company focuses on developing and operating industrial-scale data centers for Bitcoin mining and HPC hosting, aiming to be a market leader in innovation and a hosting partner to major HPC companies. With Black Pearl Phase I steadily ramping production as new rigs continue delivery, Cipher maintains its dual strategy of Bitcoin accumulation through mining operations while building infrastructure capabilities for the expanding digital asset ecosystem.\n",
    "\n",
    "The company's treasury management approach balances Bitcoin retention with operational cash flow needs, positioning Cipher as both a Bitcoin miner and strategic holder of the digital asset.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad43e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "lm = dspy.LM('openai/gpt-5-mini',\n",
    "             api_key=OPENAI_API_KEY,\n",
    "             temperature= 1.0, \n",
    "             max_tokens=16000)\n",
    "lm(messages=[{\"role\": \"user\", \n",
    "              \"content\": \"What is this company? Price range in short run? Opening in early September, Coyote Creek will offer affordable single-family homes inFort Lupton\\n\\nFORT\\xa0LUPTON, Colo.,Sept. 10, 2025/PRNewswire/ -- Century Communities, Inc. (NYSE:CCS)—a top national homebuilder, industry leader in online home sales, and featured on America's Most Trustworthy Companies and World's Most Trustworthy Companies by Newsweek—is excited to announce the Company's upcoming return to Coyote Creek inFort Lupton, boasting homesites located adjacent to the 18-hole Coyote Creek Golf Course.\\n\\nA Grand Opening celebration will take place onSaturday, September 13, from11 a.m. to 3 p.m.Attendees will enjoy light refreshments, the opportunity to win a prize giveaway, and will be among the first to tour the community's brand-new, professionally decorated model home—showcasing the community's two-story Empress floor plan.\\n\\nA Grand Opening celebration will take place onSaturday, September 13, from11 a.m. to 3 p.m.Attendees will enjoy light refreshments, the opportunity to win a prize giveaway, and will be among the first to tour the community's brand-new, professionally decorated model home—showcasing the community's two-story Empress floor plan.\\n\\nLearn more and join the community interest list atwww.CenturyCommunities.com/CoyoteCreekCO.\"}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec40ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.configure(\n",
    "    lm=dspy.LM(\n",
    "        model='openai/gpt-5-mini',\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        temperature=1.0,\n",
    "        max_tokens = 16000\n",
    "    )\n",
    ")\n",
    "\n",
    "class price_prediction_based_on_news(dspy.Signature):\n",
    "    \"\"\"\n",
    "    You are a senior finance analyst. I am passing you the news of a public company. \n",
    "    {\n",
    "      \"company\": \"company name or 'N/A'\",\n",
    "      \"ticker\": \"company ticker or 'N/A'\",\n",
    "      \"ai_comments\": \"focus on stock performance\",\n",
    "      \"short_run_days\": <float or NaN> number of days of the short run,\n",
    "      \"short_run_range_low_percent\": <float or NaN> lower end prediction of Numeric value in percentage (%) only and can be negative,\n",
    "      \"short_run_range_high_percent\": <float or NaN> higher end prediction of Numeric value in percentage (%) only and can be negative,\n",
    "      \"long_run_range_percent\": <float or NaN> long run prediction of Numeric value in percentage (%) only and can be negative\n",
    "    }\n",
    "    Include ONLY occurrences that match the target concept using provided aliases and units.\n",
    "    Do NOT include explanations; JSON array ONLY.\n",
    "    \"\"\"\n",
    "    text: str = dspy.InputField(desc=\"source text snippet\")\n",
    "    records_json: str = dspy.OutputField(desc=\"JSON array of record objects; no prose\")\n",
    "    \n",
    "pred = dspy.ChainOfThought(price_prediction_based_on_news)(text=test_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6bf2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = getattr(pred, \"records_json\", \"[]\") or \"[]\"\n",
    "# arr = json.loads(raw)\n",
    "# all_records = []\n",
    "# if arr:\n",
    "#     for item in arr:\n",
    "#         output = {\n",
    "#                     'company': item.get('company'),\n",
    "#                     'ticker': item.get('ticker', np.nan),\n",
    "#                     'short_run_days': item.get('short_run_days', np.nan),\n",
    "#                     'short_run_range_low_percent': item.get('short_run_range_low_percent', np.nan),\n",
    "#                     'short_run_range_high_percent': item.get('short_run_range_high_percent', np.nan),\n",
    "#                     'long_run_range_percent': item.get('long_run_range_percent', np.nan),\n",
    "#                     'ai_comments': item.get('ai_comments', np.nan)\n",
    "#                     }\n",
    "#         all_records.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7006a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76792e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_base.shape[0])\n",
    "df_focus = df_base[df_base['has_exchange'] == 1]\n",
    "print(df_focus.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8642059",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_base.shape[0])\n",
    "df_focus = df_base[df_base['has_exchange'] == 1]\n",
    "print(df_focus.shape[0])\n",
    "\n",
    "cnt = 0\n",
    "for idx, row in df_focus.iterrows():\n",
    "    cnt += 1\n",
    "    all_records = []\n",
    "    if cnt <= 2:\n",
    "        print(f\"Index: {idx}\")\n",
    "        print(f\"Title: {row['title']}\")\n",
    "        print(f\"Link: {row['link']}\")\n",
    "        print(\"-\" * 40)\n",
    "        pred = dspy.ChainOfThought(price_prediction_based_on_news)(text=row['content'])\n",
    "        raw = getattr(pred, \"records_json\", \"[]\") or \"[]\"\n",
    "        arr = json.loads(raw)\n",
    "        if arr:\n",
    "            for item in arr:\n",
    "                output = {  'date': row['date'],\n",
    "                            'time': row['time'],\n",
    "                            'title': row['title'],\n",
    "                            'link': row['link'],\n",
    "                            'content': row['content'],\n",
    "                            'company': item.get('company'),\n",
    "                            'ticker': item.get('ticker', np.nan),\n",
    "                            'short_run_days': item.get('short_run_days', np.nan),\n",
    "                            'short_run_range_low_percent': item.get('short_run_range_low_percent', np.nan),\n",
    "                            'short_run_range_high_percent': item.get('short_run_range_high_percent', np.nan),\n",
    "                            'long_run_range_percent': item.get('long_run_range_percent', np.nan),\n",
    "                            'ai_comments': item.get('ai_comments', np.nan)\n",
    "                            }\n",
    "                all_records.append(output)\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de5256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_focus.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
