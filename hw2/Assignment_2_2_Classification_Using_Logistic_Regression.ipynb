{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWSdntO_d7lO"
      },
      "source": [
        "Step One: Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xx2SnVDpbn0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('credit_risk_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxM0aP1E0Lfz",
        "outputId": "68be459f-d771-4f48-af72-06febb1021eb"
      },
      "outputs": [],
      "source": [
        "# Check for non-numeric values in the DataFrame\n",
        "non_numeric_cols = df.select_dtypes(include=['object']).columns\n",
        "print(f\"Non-numeric columns: {non_numeric_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfjd0Hr83xw0"
      },
      "outputs": [],
      "source": [
        "# One-hot encode the 'loan_intent', 'person_home_ownership', and other categorical variables\n",
        "df = pd.get_dummies(df, columns=['loan_intent', 'person_home_ownership', 'loan_grade', 'cb_person_default_on_file'], drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkOJerWE6bvt"
      },
      "outputs": [],
      "source": [
        "# Identify numerical columns\n",
        "numerical_cols = ['person_age', 'person_income', 'person_emp_length', 'cb_person_cred_hist_length', 'loan_amnt', 'loan_percent_income', 'loan_int_rate']\n",
        "\n",
        "# Fill missing values in numerical columns with the median\n",
        "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yWsJtV93zvs"
      },
      "source": [
        "Step Two: Train the logistic regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvUjJPNA34bG",
        "outputId": "7f58bc55-5a71-429f-8c0b-3da8d6057083"
      },
      "outputs": [],
      "source": [
        "# Ensure all values are numeric\n",
        "for col in df.columns:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Check for any remaining NaN values\n",
        "print(df.isna().sum())\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy3eZYPh43Kx"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4pex3Bv6jSp",
        "outputId": "d08f88ba-37b6-4bfb-b265-e3d0f51f4a8a"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Output model coefficients\n",
        "coefficients = pd.DataFrame({'Feature': X_train.columns, 'Coefficient': model.coef_[0]})\n",
        "print(coefficients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCPxafT89DRD"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "_aVJkNtM9FMf",
        "outputId": "af1f7aea-f126-4470-e6c3-4a146028f676"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SOaemqd9IM1",
        "outputId": "379fe3c8-408b-4434-ed32-3f04b4a59882"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-score: {f1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U67PuCtJhYB2"
      },
      "source": [
        "The logistic regression model trained to classify loan status (default or non-default) produced an accuracy of approximately 84.2%, indicating that it correctly classified 84.2% of the cases. The model's precision was 75.2%, suggesting that when it predicted a loan default, it was correct about 75.2% of the time. However, the recall was 43.0%, meaning the model identified only 43.0% of the actual defaults. The F1-score, which balances precision and recall, was 54.7%. These results indicate that while the model is generally reliable and good at predicting non-defaults, it may miss a significant number of actual defaults, highlighting the need for further refinement to improve recall and overall performance in identifying loan defaults.                                                                       \n",
        "**Microstoft Copilot was used to help generate code**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
