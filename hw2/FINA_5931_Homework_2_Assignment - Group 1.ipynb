{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZWUsw3ZUvTx"
      },
      "source": [
        "## **Objective**\n",
        "\n",
        "This assignment focuses on two key machine learning techniques: clustering analysis and classification using logistic regression. You will analyze the provided dataset (credit_risk_dataset.csv) and draw meaningful insights from your models.\n",
        "\n",
        "Data Explanation\n",
        "\n",
        "person_age: Age\n",
        "\n",
        "person_income: Annual Income\n",
        "\n",
        "person_homeownership: Home ownership\n",
        "\n",
        "person_emp_length: Employment length (in years)\n",
        "\n",
        "loan_intent: Loan intent\n",
        "\n",
        "loan_grade: Loan grade\n",
        "\n",
        "loan_amnt: Loan amount\n",
        "\n",
        "loan_int_rate: Interest rate\n",
        "\n",
        "loan_status: Loan status (0 is non-default, 1 is default)\n",
        "\n",
        "loan_percent_income: Percent income\n",
        "\n",
        "cb_person_default_on_file: Historical default\n",
        "\n",
        "cb_person_cred_hist_length: Credit history length\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y0angc38shm"
      },
      "source": [
        "#Group 1: Noah Severin, Sufyan Haroon, Jay Capozzoli"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JMWXMzyVD8z"
      },
      "source": [
        "\n",
        "# **Problem 1: Clustering Analysis**\n",
        "Task\n",
        "\n",
        "Perform a clustering analysis on the dataset to identify groups of loan applicants based on numerical variables.\n",
        "\n",
        "Steps\n",
        "\n",
        "Load the dataset and preprocess it: Handle missing values appropriately.\n",
        "\n",
        "Standardize numerical variables.\n",
        "\n",
        "Select relevant numerical columns for clustering (for example, person_age, person_income, person_emp_length, cb_person_cred_hist_length, etc.).\n",
        "\n",
        "Use the K-Means algorithm to perform clustering.\n",
        "\n",
        "Determine the optimal number of clusters using the Elbow Method.\n",
        "\n",
        "Fit the K-Means model and assign cluster labels.\n",
        "\n",
        "**Interpret the clusters:**\n",
        "\n",
        "\n",
        "*   What patterns do you observe in the clusters?\n",
        "\n",
        "\n",
        "*   How do different clusters compare in terms of loan characteristics (e.g.,\n",
        "loan amount, income, loan status)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQlRahIkMLNI"
      },
      "source": [
        "# **Problem 1 Solution: Clustering Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "My9c7zF4h6J3",
        "outputId": "f80e26e1-2444-4e7c-a2b4-f50d58972863"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "from IPython.display import display  # Import display for dataframe visualization\n",
        "\n",
        "# File path\n",
        "file_path = \"/content/credit_risk_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Handle missing values by filling with median (since numerical values may be skewed)\n",
        "df['person_emp_length'].fillna(df['person_emp_length'].median(), inplace=True)\n",
        "df['loan_int_rate'].fillna(df['loan_int_rate'].median(), inplace=True)\n",
        "\n",
        "# Select relevant numerical columns for clustering\n",
        "numerical_cols = [\n",
        "    'person_age', 'person_income', 'person_emp_length',\n",
        "    'loan_amnt', 'loan_int_rate', 'loan_percent_income',\n",
        "    'cb_person_cred_hist_length'\n",
        "]\n",
        "df_cluster = df[numerical_cols]\n",
        "\n",
        "# Standardize the numerical variables\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(df_cluster)\n",
        "\n",
        "# Determine the optimal number of clusters using the Elbow Method\n",
        "distortions = []\n",
        "K = range(1, 11)\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(df_scaled)\n",
        "    distortions.append(sum(np.min(cdist(df_scaled, kmeans.cluster_centers_, 'euclidean'), axis=1)) / df_scaled.shape[0])\n",
        "\n",
        "# Plot the Elbow Method chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(K, distortions, marker='o')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Average Distortion')\n",
        "plt.title('Elbow Method for Optimal Clusters')\n",
        "plt.show()\n",
        "\n",
        "# Based on the elbow method, let's choose an optimal k (e.g., 4) for clustering\n",
        "optimal_k = 4\n",
        "\n",
        "# Fit the K-Means model with the chosen number of clusters\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "df['cluster'] = kmeans.fit_predict(df_scaled)\n",
        "\n",
        "# Analyze the clusters by summarizing key characteristics\n",
        "cluster_summary = df.groupby('cluster')[numerical_cols].mean()\n",
        "\n",
        "# Display cluster analysis summary using display()\n",
        "print(\"Cluster Analysis Summary:\")\n",
        "display(cluster_summary)  # Use display() to show the dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RD5f5aGeJMV"
      },
      "source": [
        "# ***Characteristic Comparison:***\n",
        "The clusters revealed distinct borrower profiles based on age, income, credit history, and loan characteristics. Cluster 0 consists of the youngest borrowers 25.6 years old with the lowest income of 5498 and shortest credit history of 4.46 years. They receive the smallest loans of 6,288 but at the highest interest rates 12.94% due to their high-risk profile.\n",
        "\n",
        "Cluster 1 includes slightly older borrowers 26.3 years with higher incomes of 68,437 but takes on the largest loans 17,309 with the highest loan-to-income ratio 0.29. Their moderate credit history of 4.91 years helps them secure a lower interest rate of 11.98% than Cluster 0.\n",
        "\n",
        "Cluster 2 are similar to Cluster 1 in age and income but borrows conservatively 7,211 with the lowest loan-to-income ratio 0.12. They receive the lowest interest rates of 8.05%, making them the safest borrowers.\n",
        "\n",
        "Cluster 3 represents the most financially stable cluster, with the oldest borrowers being 40.9 years, highest income of 86,989, longest employment of\n",
        "6.35 years, and strongest credit history of 14.27 years. They take on  moderate loans amount of 9,784 at 11.18% interest rate.\n",
        "\n",
        "# ***Key patterns:***\n",
        "\n",
        "*Loan amount:* Cluster 1 borrows the most, Cluster 0 the least.\n",
        "\n",
        "*Interest rates:* Cluster 2 enjoys the lowest, Cluster 0 the highest.\n",
        "\n",
        "*Loan-to-income ratio:* Cluster 1 is the most leveraged, Cluster 2 the most conservative.\n",
        "\n",
        "*Credit history:* Cluster 3 is the strongest, Cluster 0 the weakest.\n",
        "Overall, Cluster 2 is the safest, Cluster 1 the riskiest, and Cluster 3 the most established."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtVXJ7JYV07f"
      },
      "source": [
        "# **Problem 2: Classification Using Logistic Regression**\n",
        "**Task**\n",
        "\n",
        "Choose one meaningful categorical variable from the dataset and build a logistic regression model to classify loan status (default or non-default).\n",
        "\n",
        "**Steps**\n",
        "\n",
        "1. Select a categorical variable (e.g., cb_person_default_on_file, loan_grade, or loan_intent).\n",
        "\n",
        "2. **Preprocess data:** Convert categorical variables into numerical form (e.g., one-hot encoding or label encoding).\n",
        "\n",
        "3. Handle missing values if applicable.\n",
        "\n",
        "4. Split the data into training and testing sets.\n",
        "\n",
        "5. Train a logistic regression model to predict loan_status (0 or 1).\n",
        "\n",
        "6. **Evaluate model performance using:**\n",
        "Confusion matrix\n",
        "Accuracy, Precision, Recall, and F1-score\n",
        "\n",
        "7. Interpret results:\n",
        "What insights can you gain from the logistic regression model?\n",
        "What features are most important for predicting loan defaults?\n",
        "How reliable is the model for making predictions?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnexGz4-WltE"
      },
      "source": [
        "# **Problem 2 Solution: Classification Using Logistic Regression**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "WJYXwioqWfvk",
        "outputId": "07cb50b6-673e-4496-d48e-23928b10c8c3"
      },
      "outputs": [],
      "source": [
        "#Import\n",
        "import kagglehub\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    accuracy_score\n",
        ")\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rwhi0F_Td3H",
        "outputId": "9c41cd30-06e6-4ff6-93d6-f82c555bc5f2"
      },
      "outputs": [],
      "source": [
        "# Check the data columns\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OgZwC0pTkAA",
        "outputId": "6246c3eb-12f4-4d56-a281-b4fdb38a2dfa"
      },
      "outputs": [],
      "source": [
        "# Check data info\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79baif1qTmye",
        "outputId": "6e680513-85b1-4d1d-f950-a8aeebfb0495"
      },
      "outputs": [],
      "source": [
        "# Strip whitespace from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = ['person_home_ownership', 'loan_intent','loan_grade', 'cb_person_default_on_file']\n",
        "\n",
        "# present all unique values per categorical columns\n",
        "for col in categorical_cols:\n",
        "    print(f'for column {col}, the unique values are')\n",
        "    print(df[col].unique())\n",
        "\n",
        "# Apply one-hot encoding to categorical columns\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrR2xsQlTrWS",
        "outputId": "f54cb5b6-a898-4629-e2ba-b4ffae3d8c6d"
      },
      "outputs": [],
      "source": [
        "df_encoded.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aEK7lBE9Ttlk",
        "outputId": "80b763be-0892-46d4-be20-765449174715"
      },
      "outputs": [],
      "source": [
        "# Categorical Variable Chosen: Defaults on File 'cb_person default_on_file'\n",
        "# Drop columns for selected target and categorical variables not chosen\n",
        "selected_features = [col for col in df_encoded.columns\n",
        "                     if col not in [\"loan_status\",\n",
        "                                     \"person_home_ownership_OTHER\",\n",
        "                                     \"person_home_ownership_OWN\",\n",
        "                                     \"person_home_ownership_RENT\",\n",
        "                                     \"loan_intent_EDUCATION\",\n",
        "                                     \"loan_intent_HOMEIMPROVEMENT\",\n",
        "                                     \"loan_intent_MEDICAL\",\n",
        "                                     \"loan_intent_PERSONAL\",\n",
        "                                     \"loan_intent_VENTURE\",\n",
        "                                     \"loan_grade_B\",\n",
        "                                     \"loan_grade_C\",\n",
        "                                     \"loan_grade_D\",\n",
        "                                     \"loan_grade_E\",\n",
        "                                     \"loan_grade_F\",\n",
        "                                     \"loan_grade_G\",\n",
        "                                    ]]\n",
        "target = \"loan_status\"\n",
        "\n",
        "# Features and target\n",
        "X = df_encoded[selected_features]\n",
        "y = df_encoded[target]\n",
        "\n",
        "# Compute correlation between features and loan_status (default risk)\n",
        "correlation_matrix = df_encoded.corr()\n",
        "\n",
        "# Extract correlations related to loan_status\n",
        "loan_correlation = correlation_matrix[\"loan_status\"].drop(\"loan_status\").sort_values(ascending=False)\n",
        "print(\"\\nFeature Correlation with Default Risk:\\n\", loan_correlation)\n",
        "\n",
        "# Plot correlation heatmap\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", annot=False, linewidths=0.5)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Split data into training and testing sets (75% training, 25% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)\n",
        "\n",
        "# Initialize logistic regression model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Drop rows with any missing values in the training and testing sets\n",
        "X_train = X_train.dropna()\n",
        "y_train = y_train[X_train.index]  # Make sure y_train aligns with X_train after dropping rows\n",
        "X_test = X_test.dropna()\n",
        "y_test = y_test[X_test.index]  # Make sure y_test aligns with X_test after dropping rows\n",
        "\n",
        "# Train the model\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions and probabilities\n",
        "y_pred = log_reg.predict(X_test)\n",
        "y_pred_prob = log_reg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"df_encoded = 0\", \"df_encoded = 1\"], yticklabels=[\"df_encoded = 0\", \"df_encoded = 1\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Classification Report for precision, recall, F1-score\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLRzUFlErqAr"
      },
      "source": [
        "# ***Analysis***\n",
        "\n",
        "The logistic regression model provided valuable insights into predicting loan defaults, but it also highlighted areas for improvement. The model has an  accuracy of 82.4%, the model performs well overall, particularly in identifying non-defaulters. However, the confusion matrix and classification report reveal a significant discrepincies in predictive performance. The model achieves 96% recall for non-defaulters, meaning that it correctly identifies most individuals who will repay their loans. In comparison, it only captures 35% of actual defaulters, meaning a substantial number of defaulters are incorrectly classified as non-defaulters. This misclassification is a major concern in loan risk assessment, as failing to identify high-risk borrowers can lead to financial losses.\n",
        "\n",
        "In terms of feature importance, key factors  influencing loan defaults include loan income ratio, loan interest rate, and loan grade. Borrowers with a higher loan-to-income ratio (0.379 correlation) are more likely to default, as higher debt burdens make repayments difficult. Similarly, high interest rates (0.335 correlation) increase default risk by raising monthly payments. Loan grades also play a significant role, with lower-grade loans showing strong positive correlations with default, indicating that riskier loans are more prone to failure. Alternatively, higher income (-0.144 correlation), homeownership (-0.102), and longer employment history (-0.082) are associated with lower default risk, as they indicate stronger financial security. These factors should be prioritized when assessing loan risk.\n",
        "\n",
        "Despite its high overall accuracy, the model is not entirely reliable for predicting defaults due to its low recall for defaulters. This suggests a bias toward the non-defaulters. This is likely due to class imbalance in the dataset, as majority of them are non-defaulters. Overall, while the model effectively identifies non-defaulters, its low recall for defaulters makes it less reliable for financial decision-making, particularly in risk assessment.If used lenders will contibue to underestimate default probabilities, leading to potential financial exposure.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
