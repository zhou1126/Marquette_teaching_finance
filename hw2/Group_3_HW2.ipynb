{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzV0_E5unwiI"
      },
      "source": [
        "HW 2\n",
        "Group 3\n",
        "Problem 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeBVN_NeQZSd"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    accuracy_score\n",
        ")\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "HzCg07mDQn0c",
        "outputId": "a74d47fd-711b-420a-c033-1642eb935860"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vFtWYL0RF8t",
        "outputId": "7d560672-919d-4123-825e-c0c8d40c92b2"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqpu-cZCRaAW",
        "outputId": "5f335bbf-ccf6-41fa-cbd6-2dd5b09dbe94"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "NEKOfna0ThOg",
        "outputId": "852cc6ca-c83e-49d7-f3bd-22e07dff084f"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "numerical_cols = ['person_age', 'person_income','person_emp_length', 'loan_amnt', 'loan_int_rate','cb_person_cred_hist_length']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7x0xg1YSpia"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "df=df.dropna()\n",
        "df.columns = df.columns.str.strip()\n",
        "columns_for_clustering = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'cb_person_cred_hist_length']\n",
        "X=df[columns_for_clustering]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "a950lWoVTHnZ",
        "outputId": "fbeb6945-a2ca-4d2a-9726-e24b639a7360"
      },
      "outputs": [],
      "source": [
        "# Elbow Method\n",
        "inertia = []\n",
        "silhouette_scores = []\n",
        "range_n_clusters = range(2, 11)  # Test for 2 to 10 clusters\n",
        "\n",
        "for k in range_n_clusters:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=20).fit(X)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "    silhouette_scores.append(silhouette_score(X, kmeans.labels_))\n",
        "\n",
        "# Plot Inertia and Silhouette Score\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range_n_clusters, inertia, marker='o')\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Inertia')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range_n_clusters, silhouette_scores, marker='o', color='green')\n",
        "plt.title('Silhouette Score')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qae-gU3RpYK"
      },
      "source": [
        "We are selecting 7 clusters as the optimal number per the elbow method. It is where the slope of the inertia slows down significantly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqMCVdMEWSeD",
        "outputId": "9ee20bce-104d-4074-ef3c-0039e49be6e5"
      },
      "outputs": [],
      "source": [
        "optimal_clusters = 7\n",
        "\n",
        "# K-Means Clustering\n",
        "kmeans = KMeans(n_clusters=optimal_clusters, random_state=20).fit(X)\n",
        "X['Cluster'] = kmeans.labels_\n",
        "\n",
        "df['Cluster'] =  kmeans.labels_\n",
        "cluster_analysis = df.groupby('Cluster').agg(person_age = ('person_age', 'mean'),\n",
        "                                                      person_income = ('person_income', 'mean'),\n",
        "                                                      person_emp_length = ('person_emp_length', 'mean'),\n",
        "                                                      loan_amnt = ('loan_amnt', 'mean'),\n",
        "                                                      loan_int_rate = ('loan_int_rate', 'mean'),\n",
        "                                                      cb_person_cred_hist_length = ('cb_person_cred_hist_length', 'mean'),\n",
        "                                                      num_comp= ('person_age', 'count')\n",
        "                                                      ).reset_index()\n",
        "\n",
        "print(\"Cluster Analysis (Means and Record Counts):\\n\", cluster_analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z353911gYG38"
      },
      "source": [
        "Question 4: Looking at the data, the size of each cluster varies a lot from 2320 to 7484. The data in the largest cluster has the lowest interest rates, is the 2nd youngest cluster. Cluster 4 is the oldest cluster by far and has the longest credit history length. Cluster five has the highest income and highest loan amounts. The clusters seem to make sense how the model grouped people together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r_AZhT4Z0YE"
      },
      "source": [
        "Problem 2 - Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gvEqY-EZwwd",
        "outputId": "e8770db5-5db6-42df-9fe8-3752388c131a"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "categorical_cols = ['loan_intent']\n",
        "\n",
        "# present all unique values per categorical columns\n",
        "for col in categorical_cols:\n",
        "    print(f'for column {col}, the unique values are')\n",
        "    print(df[col].unique())\n",
        "\n",
        "# Apply one-hot encoding to categorical columns\n",
        "selected_columns = ['loan_intent','loan_status']\n",
        "new_df=df[selected_columns]\n",
        "df_encoded = pd.get_dummies(new_df, columns=categorical_cols, drop_first=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHwOQw3IbfzJ",
        "outputId": "9c96e09e-1d7f-4c5c-8a9a-cbea94dd0b3c"
      },
      "outputs": [],
      "source": [
        "df_encoded.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "ua3OTqznavcm",
        "outputId": "7b01a1c3-728a-4117-a611-52c9a43d20a5"
      },
      "outputs": [],
      "source": [
        "grouped_averages = df_encoded.groupby(\"loan_status\").mean()\n",
        "\n",
        "# Display the grouped averages\n",
        "grouped_averages.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nOb0IrPyd3Sa",
        "outputId": "6be326a2-30a0-485a-9668-4a884d1d39bf"
      },
      "outputs": [],
      "source": [
        "selected_features = df_encoded.columns.drop(\"loan_status\")\n",
        "target = \"loan_status\"\n",
        "# Features and target\n",
        "X = df_encoded[selected_features]\n",
        "y = df_encoded[target]\n",
        "\n",
        "# Split data into training and testing sets (75% training, 25% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)\n",
        "\n",
        "# Initialize logistic regression model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions and probabilities\n",
        "y_pred = log_reg.predict(X_test)\n",
        "y_pred_prob = log_reg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"df_encoded = 0\", \"df_encoded = 1\"], yticklabels=[\"df_encoded = 0\", \"df_encoded = 1\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Classification Report for precision, recall, F1-score\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# AUC (Area Under the Curve)\n",
        "auc_score = roc_auc_score(y_test, y_pred_prob)\n",
        "print(\"AUC:\", auc_score)\n",
        "\n",
        "# Plot ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_score:.2f})\", color=\"blue\")\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random Classifier\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57DOnvS4d-pD"
      },
      "source": [
        "The model we created predicted that everyone would be denied for a loan based solely on the loan intent variable. This wouldn't be a good model to use, because there were 1,422 data points classified incorrectly. It says that it is 78% accurate but this is just because of the data set. Because the AUC is about .5, but we know the model is not working and just denying all the loans. The f1 score is .88 for denying loans but 0 for approving loans. The threshold may be too high which is why it is denying every loan. Based on this model, we cannot determine which variable is most important. It is not a reliable model for making predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmeHB_SKmqXi"
      },
      "source": [
        "Part 3 Group Survey:\n",
        "Course Rating - 4, Difficulty Level - 4\n",
        "Pros: The content is interesting and applicable. We appreciate the guidance with providing the code. Guest speakers are also interesting.\n",
        "Cons: The lectures are very content heavy and it can be difficult to digest it all. For those that don't have much experience coding it can be difficult to deal with errors in the code.\n",
        "Suggestions: Maybe taking more time to go through the code in more detail so we can understand what you are doing better."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
