{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5HIIf2jBaWp",
        "outputId": "f3e9f9d3-2d8a-4a79-de02-b9fc19489d27"
      },
      "outputs": [],
      "source": [
        "# Problem 1 CAPM Model\n",
        "# 1. Data Retrieval\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# Step 1: Fetch Data\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2024-12-31\"\n",
        "risk_free_ticker = \"^IRX\"  # Use the 13-week Treasury yield as a proxy for risk-free rate\n",
        "market_index_ticker = \"^GSPC\"  # S&P 500 index\n",
        "equity_tickers = [\"NVDA\"]  # Replace with desired stock tickers\n",
        "\n",
        "# Fetch data\n",
        "risk_free_data = yf.download(risk_free_ticker, start=start_date, end=end_date)[\"Close\"]\n",
        "market_data = yf.download(market_index_ticker, start=start_date, end=end_date)[\"Close\"]\n",
        "stock_data = yf.download(equity_tickers, start=start_date, end=end_date)[\"Close\"]\n",
        "#1.2 Excess Returns\n",
        "# Step 2: Prepare Data\n",
        "# Calculate daily returns\n",
        "market_returns = market_data.pct_change().dropna()\n",
        "stock_returns = stock_data.pct_change().dropna()\n",
        "\n",
        "# Convert risk-free rate from percentage to daily rate\n",
        "risk_free_rate = risk_free_data / 100 / 252\n",
        "risk_free_rate = risk_free_rate.reindex(market_returns.index, method=\"ffill\")\n",
        "\n",
        "# convert to pandas dataframe\n",
        "risk_free_rate = pd.DataFrame(risk_free_rate).dropna()\n",
        "\n",
        "# Merge All data together\n",
        "merged_df = pd.merge(stock_returns,\n",
        "                    pd.merge(market_returns, risk_free_rate,\n",
        "                            left_index=True, right_index=True),\n",
        "                    left_index=True, right_index=True)\n",
        "\n",
        "# Calculate cumulative return\n",
        "for col in merged_df.columns:\n",
        "    merged_df[f\"{col}_cumu_return\"] = (1 + merged_df[col]).cumprod()\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Assuming stock_data['NVDA'] contains the data for NVIDIA's stock\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add a line plot for NVIDIA stock prices\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=stock_data.index,  # Assuming the index contains dates\n",
        "    y=stock_data['NVDA'],\n",
        "    mode='lines',\n",
        "    name='NVIDIA Stock Prices'\n",
        "))\n",
        "\n",
        "# Customize the layout\n",
        "fig.update_layout(\n",
        "    title='NVIDIA Stock Price Over Time',\n",
        "    xaxis_title='Date',\n",
        "    yaxis_title='Price',\n",
        "    template='plotly_white',\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "selected = 'NVDA'\n",
        "comparable = '^GSPC'\n",
        "# Assuming merged_df['NVDA'] contains the data for NVIDIA's stock\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add a line plot for NVIDIA stock prices\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=merged_df.index,  # Assuming the index contains dates\n",
        "    y=merged_df[f'{selected}_cumu_return'],\n",
        "    mode='lines',\n",
        "    name=f'{selected} Cumulative Return'\n",
        "))\n",
        "\n",
        "if comparable != '':\n",
        "    # Add a line plot for NVIDIA stock prices\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=merged_df.index,  # Assuming the index contains dates\n",
        "        y=merged_df[f'{comparable}_cumu_return'],\n",
        "        mode='lines',\n",
        "        name=f'{comparable} Cumulative Return'\n",
        "    ))\n",
        "\n",
        "    # Customize the layout\n",
        "    fig.update_layout(\n",
        "        title=f'{selected} and {comparable} Daily Return',\n",
        "        xaxis_title='Date',\n",
        "        yaxis_title='Price',\n",
        "        template='plotly_white',\n",
        "        showlegend=True\n",
        "    )\n",
        "else:\n",
        "    # Customize the layout\n",
        "    fig.update_layout(\n",
        "        title=f'{selected} Daily Returm',\n",
        "        xaxis_title='Date',\n",
        "        yaxis_title='Price',\n",
        "        template='plotly_white',\n",
        "        showlegend=True\n",
        "    )\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "# Calculate market excess return\n",
        "merged_df['market_excess_return'] = merged_df['^GSPC'] - merged_df['^IRX']\n",
        "merged_df['dt'] = merged_df.index\n",
        "#1.3 CAPM Estimation\n",
        "# use CAPM model\n",
        "stock = 'NVDA'\n",
        "\n",
        "# Stock excess return ~ market excess return\n",
        "y = merged_df[stock] - merged_df['^IRX']\n",
        "x = merged_df['market_excess_return']\n",
        "x = sm.add_constant(x)\n",
        "model = sm.OLS(y, x).fit()\n",
        "# Extract parameters\n",
        "alpha, beta = model.params\n",
        "r_squared = model.rsquared\n",
        "# Display results\n",
        "print(f\"CAPM Model for {stock}:\")\n",
        "print(f\"Alpha (Intercept):{alpha}\")\n",
        "print(f\"Beta (Slope):{beta}\")\n",
        "print(f\"R-squared: {r_squared}\")\n",
        "#1.4 Analysis\n",
        "# ****Analysis: Because the Beta for Nvidia is 2.3, it is significantly more volitile than the market. The graph below shows that a slight change in the market return will cause a large change in Nividia return. ***\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(merged_df['market_excess_return'], y, alpha=0.6, label=\"Excess Returns Data\")\n",
        "\n",
        "# Regression line\n",
        "x_range = np.linspace(min(merged_df['market_excess_return']), max(merged_df['market_excess_return']), 100)\n",
        "y_pred = alpha + beta * x_range  # Regression equation\n",
        "plt.plot(x_range, y_pred, color='red', label=f\"Regression Line: y = {alpha} + {beta}x\")\n",
        "\n",
        "# Labels and Title\n",
        "plt.xlabel(\"Market Excess Return\")\n",
        "plt.ylabel(f\"{stock} Excess Return\")\n",
        "plt.title(f\"CAPM Regression: {stock} vs Market Excess Returns\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Problem 2: Fama-French Three-Factor Model\n",
        "# 2.1 Data Retrieval - downloaded .csv name F-F_Research_Data_Factors_daily\n",
        "# 2.2 Excess Returns\n",
        "FF_df = pd.read_csv('F-F_Research_Data_Factors_daily.CSV')\n",
        "FF_df['Date'] = pd.to_datetime(FF_df['Date'], format='%Y%m%d')\n",
        "FF_df['Mkt-RF'] = FF_df['Mkt-RF']/100\n",
        "FF_df['SMB'] = FF_df['SMB']/100\n",
        "FF_df['HML'] = FF_df['HML']/100\n",
        "FF_df['RF'] = FF_df['RF']/100\n",
        "\n",
        "\n",
        "# Merge the FF Factors to Stocks\n",
        "stock_returns = stock_returns.merge(FF_df, on = 'Date', how = 'inner')\n",
        "\n",
        "# Calculate NVDA excess return\n",
        "stock = 'NVDA'\n",
        "stock_returns['NVDA_Excess_Return'] = stock_returns[stock] - stock_returns['RF']\n",
        "\n",
        "print(stock_returns[['Date', stock, 'RF', 'NVDA_Excess_Return']].head())\n",
        "\n",
        "# 2.3 Model Estimation\n",
        "y = stock_returns[stock] - stock_returns['RF']\n",
        "x = stock_returns[['Mkt-RF', 'SMB', 'HML']]\n",
        "# get alpha for ff model\n",
        "ffx = sm.add_constant(x)\n",
        "model = sm.OLS(y, ffx).fit()\n",
        "print(f\"FF model\")\n",
        "print(model.summary())\n",
        "#2.4 Analysis: Compare the R-squared values of the CAPM and Three-Factor Model.\n",
        "# The R-squared of the three CAPM model was .515 while the Three-Factor Model had an R-squared of .585. This means that more of the variation in Nvidia excess returns is due to the market when using the Three-Factor Model than is when using CAPM. This is because the Three-Factor Model incorporates more data into the R-squared and therefore should be more accurate.\n",
        "\n",
        "# Interpret the SMB and HML coefficients to discuss size and value effects.\n",
        "# The SMB coeficient is -.54 which indicates that the stock is large cap. This makes sense because Nvidia is the top 5 largest companies in terms of market cap and is currently valued at $3.4 trillion.\n",
        "# The HML coeficient is almost negative 1 which means that the stock has a veru book to market ratio and is a growth stock. In this case, the HML coeficient means that the market expects Nvidia to have significant growth in the coming years.\n",
        "# The results for both coeficients also have a P value of 0.000 so the coefiecients are significant.\n",
        "#3.1 Data Retrieval\n",
        "equity_ticker_new = [\"AAPL\", \"MSFT\", \"AMZN\", \"TSLA\", \"JPM\", \"PFE\", \"KO\", \"XOM\", \"NVDA\", \"META\"]\n",
        "stock_data_new = yf.download(equity_ticker_new, start=start_date, end=end_date, progress=False)['Close']\n",
        "#3.2 Calculate daily returns\n",
        "stock_returns_new = stock_data_new.pct_change().dropna()\n",
        "print(stock_returns_new.head())\n",
        "\n",
        "#3.1 Data Retrieval\n",
        "equity_ticker_new = [\"AAPL\", \"MSFT\", \"AMZN\", \"TSLA\", \"JPM\", \"PFE\", \"KO\", \"XOM\", \"NVDA\", \"META\"]\n",
        "stock_data_new = yf.download(equity_ticker_new, start=start_date, end=end_date, progress=False)['Close']\n",
        "#3.2 Calculate daily returns\n",
        "stock_returns_new = stock_data_new.pct_change().dropna()\n",
        "print(stock_returns_new.head())\n",
        "\n",
        "#3.2.2 Compute summary statistics (done completing regression for all 10 stocks)\n",
        "# Merge the FF Factors to Stocks\n",
        "stock_returns_new = stock_returns_new.merge(FF_df, on = 'Date', how = 'inner')\n",
        "for stock in equity_ticker_new:\n",
        "    print(f\"Summary statistics for {stock}:\")\n",
        "    y = stock_returns_new[stock] - stock_returns_new['RF']  # Stock Excess Return\n",
        "    x = stock_returns_new[['Mkt-RF', 'SMB', 'HML']]  # Fama-French Factors\n",
        "    x = sm.add_constant(x)\n",
        "    model = sm.OLS(y, x).fit()\n",
        "\n",
        "    # Print full model summary\n",
        "    print(model.summary())\n",
        "#3.3 Clustering\n",
        "# Combine w/ additional data\n",
        "all_betas = []\n",
        "for stock in equity_ticker_new:\n",
        "    y = stock_returns_new[stock] - stock_returns_new['RF']\n",
        "    x = stock_returns_new[['Mkt-RF', 'SMB', 'HML']]\n",
        "    model = sm.OLS(y, x).fit()\n",
        "    temp = {'Ticker': stock,\n",
        "            'MKT_excess_beta': model.params['Mkt-RF'],\n",
        "            'SMB_beta': model.params['SMB'],\n",
        "            'HML_beta': model.params['HML']}\n",
        "    all_betas.append(temp)\n",
        "\n",
        "all_beta_df = pd.DataFrame(all_betas)\n",
        "# get 'ticker', 'name', 'market_cap', 'sector', 'industry'and merge\n",
        "stock_info = []\n",
        "for ticker in equity_ticker_new:\n",
        "    stock = yf.Ticker(ticker)\n",
        "    stock_data = stock.info  # Fetch metadata\n",
        "\n",
        "    temp = {'Ticker': ticker,\n",
        "            'Name': stock_data.get('longName', 'N/A'),\n",
        "            'Market Cap': stock_data.get('marketCap', 'N/A'),\n",
        "            'Sector': stock_data.get('sector', 'N/A'),\n",
        "            'Industry': stock_data.get('industry', 'N/A')}\n",
        "\n",
        "    stock_info.append(temp)\n",
        "stock_info_df = pd.DataFrame(stock_info)\n",
        "stock_info_df = stock_info_df[['Ticker', 'Name', 'Market Cap', 'Sector', 'Industry']]\n",
        "\n",
        "all_beta_df = all_beta_df.merge(stock_info_df, on='Ticker', how='left')\n",
        "\n",
        "\n",
        "\n",
        "print(all_beta_df)\n",
        "\n",
        "#3.3 continued Normalize and use k-means clustering to group the stocks into 3 clusters\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "columns_for_clustering = ['MKT_excess_beta', 'SMB_beta', 'HML_beta']\n",
        "X = all_beta_df[columns_for_clustering]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "#3.4 Visualize\n",
        "optimal_clusters = 3\n",
        "\n",
        "# K-Means Clustering\n",
        "kmeans = KMeans(n_clusters=optimal_clusters, random_state=20)\n",
        "all_beta_df['Cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=all_beta_df['Cluster'], cmap='viridis', edgecolors='k', s=100)\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=250, marker='X', c='red', edgecolors='k', label=\"Centroids\")\n",
        "for i, ticker in enumerate(all_beta_df['Ticker']):\n",
        "    plt.text(X_scaled[i, 0], X_scaled[i, 1], ticker, fontsize=9, ha='right', va='bottom')\n",
        "for i, (x, y) in enumerate(zip(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1])):\n",
        "    plt.text(\n",
        "        x, y - 0.15, f\"{i}\",\n",
        "        fontsize=10, fontweight='bold', ha='center', va='top', color='black'\n",
        "    )\n",
        "plt.title(\"K-Means Clustering of Stocks (3 Clusters)\")\n",
        "plt.xlabel('MKT_excess_beta (Normalized)')\n",
        "plt.ylabel('SMB_beta (Normalized)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "all_beta_df['Cluster'] =  kmeans.labels_\n",
        "cluster_analysis = all_beta_df.groupby('Cluster').agg(\n",
        "    mean_MKT_excess_beta=('MKT_excess_beta', 'mean'),\n",
        "    mean_SMB_beta=('SMB_beta', 'mean'),\n",
        "    mean_HML_beta=('HML_beta', 'mean'),\n",
        "    mean_market_cap=('Market Cap', 'mean'),  # Ensure column name matches\n",
        "    num_comp=('Ticker', 'count')\n",
        ").reset_index()\n",
        "\n",
        "print(\"Cluster Analysis (Means and Record Counts):\\n\", cluster_analysis)\n",
        "cluster_analysis\n",
        "# Distribution of sectors across clusters\n",
        "sector_distribution = all_beta_df.groupby(['Cluster', 'Sector']).size().reset_index(name='sector_count')\n",
        "\n",
        "# Distribution of industries across clusters\n",
        "industry_distribution = all_beta_df.groupby(['Cluster', 'Industry']).size().reset_index(name='industry_count')\n",
        "\n",
        "# Top 3 most frequent sectors per cluster\n",
        "top_sectors = sector_distribution.groupby('Cluster').apply(lambda x: x.nlargest(3, 'sector_count')).reset_index(drop=True)\n",
        "\n",
        "# Top 3 most frequent industries per cluster\n",
        "top_industries = industry_distribution.groupby('Cluster').apply(lambda x: x.nlargest(3, 'industry_count')).reset_index(drop=True)\n",
        "\n",
        "# Print the results\n",
        "print(\"Top 3 Most Frequent Sectors per Cluster:\\n\", top_sectors)\n",
        "print(\"\\nTop 3 Most Frequent Industries per Cluster:\\n\", top_industries)\n",
        "#3.5 - Analysis:Interpret the clusters and discuss potential similarities among stocks in the same cluster.\n",
        "# The clusters of stock appear to be organized into tech, auto, and other categories. Because Tesla is the only car company in the data and is a very unique company, it has its own cluster. Apple, Amazon, Microsoft, Meta, and Nvidia are another cluster. These are all tech stocks with similar movement in the stock martket. The last cluster appears to be all of the stocks that did not fit in the other two. If we were to add more stocks and clusters, they would be organized into more detailed categories.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
